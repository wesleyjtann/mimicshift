{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6521b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import sys\n",
    "import numpy as np\n",
    "import hashlib\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "from scipy import stats\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "def getAgentHash(agent, agentHashRange) :\n",
    "    hashret = int(hashlib.sha1(agent.encode('utf-8')).hexdigest(), 16) % agentHashRange\n",
    "\n",
    "    return str(hashret)\n",
    "\n",
    "def loadConfig():\n",
    "    with open(sys.argv[1], \"r\") as ymlfile:\n",
    "        cfg = yaml.load(ymlfile)\n",
    "    return cfg\n",
    "\n",
    "def getHash(fullURI, queryHashRange):\n",
    "    hashret = 0\n",
    "\n",
    "    #Handles cases with no '/'\n",
    "    if(fullURI.find('/') == -1) :\n",
    "        fullURI = '/' + fullURI\n",
    "\n",
    "    uri = fullURI.split('?', 1)[0]\n",
    "\n",
    "    if (len(uri.rsplit('/', 1)) > 1) :\n",
    "        request = uri.rsplit('/', 1)[1]\n",
    "    else :\n",
    "        request = ''\n",
    "\n",
    "    if (len(fullURI.split('?', 1)) > 1) :\n",
    "        request = request + '?' + fullURI.split('?', 1)[1]\n",
    "    else :\n",
    "        request = request\n",
    "\n",
    "    hashret = int(hashlib.sha1(request.encode('utf-8')).hexdigest(), 16) % queryHashRange\n",
    "    uri = uri.rsplit('/', 1)[0]\n",
    "\n",
    "    return str(hashret)\n",
    "\n",
    "def getURI(fullURI):\n",
    "    uri = fullURI.split('?', 1)[0]\n",
    "    uri = uri.rsplit('/', 1)[0]\n",
    "\n",
    "\n",
    "    if uri == '' :\n",
    "        return '<EMPTY>'\n",
    "    else :\n",
    "        return str(uri)\n",
    "\n",
    "def converttodatetime(x, seqlen):\n",
    "    # if len(x)< 20:\n",
    "    if len(x)< seqlen:    # add\n",
    "        x += '.000'\n",
    "    return datetime.datetime.strptime(x, \"%Y-%m-%d %H:%M:%S.%f\")\n",
    "\n",
    "#TimeDif 0 Padding\n",
    "# Start = 14\n",
    "# End = 15\n",
    "def getTimeClass(time_dif):\n",
    "    time = 0\n",
    "    if time_dif == 0.0:\n",
    "        time = 0\n",
    "    elif time_dif < 0.001 :\n",
    "        time = 1\n",
    "    elif time_dif < 0.05 :\n",
    "        time = 2\n",
    "    elif time_dif < 0.1 :\n",
    "        time = 3\n",
    "    elif time_dif < 1 :\n",
    "        time = 4\n",
    "    elif time_dif < 15 :\n",
    "        time = 5\n",
    "    elif time_dif < 180 :\n",
    "        time = 6\n",
    "    elif time_dif > 300 :\n",
    "        time = 7\n",
    "\n",
    "    return str(time)\n",
    "\n",
    "#Source IP  Dest IP Time    Packet Len  IP Flags    TCP Len TCP Ack TCP Flags   TCP Window Size UDP Len ICMP Type   Protocols   Highest Layer(Protocol) Info\n",
    "def prepDataFrame(df, agentHashRange, queryHashRange) :\n",
    "    #create a deepcopy of the original df\n",
    "    df_temp = df.copy()\n",
    "    if type(df_temp['Absolute Time'].iloc[0]) == str:\n",
    "        df_temp['Absolute Time'] = df_temp['Absolute Time'].apply(lambda x: converttodatetime(x, config['SEQUENCELENGTH'])) # add\n",
    "\n",
    "    #converting type of status\n",
    "    df_temp = df_temp.astype({'Source IP' : 'str'})\n",
    "    df_temp = df_temp.astype({'Dest IP' : 'str'})\n",
    "    # df_temp = df_temp.astype({'Relative Time' : 'str'})\n",
    "    df_temp = df_temp.astype({'Packet Len': 'str'})\n",
    "    df_temp = df_temp.astype({'IP Flags' : 'str'})\n",
    "    df_temp = df_temp.astype({'TCP Len' : 'str'})\n",
    "    df_temp = df_temp.astype({'TCP Flags' : 'str'})\n",
    "    df_temp = df_temp.astype({'TCP Window Size': 'str'})\n",
    "    df_temp = df_temp.astype({'Protocols': 'str'})\n",
    "    df_temp = df_temp.astype({'Highest Layer(Protocol)': 'str'})\n",
    "    df_temp = df_temp.astype({'Info' : 'str'})\n",
    "\n",
    "    ##TCP ACK Feature Engineering\n",
    "    tcpack = np.array(df_temp['TCP Ack'])\n",
    "    bin_edges = stats.mstats.mquantiles(tcpack, np.arange(0,1,0.01)[1:])\n",
    "\n",
    "    df_temp.loc[df_temp['TCP Ack'] <= bin_edges[int(0)], 'new TCP Ack'] = int(0)\n",
    "\n",
    "    for i in range(len(bin_edges)-1):\n",
    "        df_temp.loc[(bin_edges[int(i)] < df_temp['TCP Ack']) & (df_temp['TCP Ack'] <= bin_edges[int(i+1)]), 'new TCP Ack'] = int(i+1)\n",
    "\n",
    "    df_temp.loc[df_temp['TCP Ack'] > bin_edges[-1], 'new TCP Ack'] = int(len(bin_edges))\n",
    "    df_temp['new TCP Ack'] = df_temp['new TCP Ack'].astype('str')\n",
    "\n",
    "    #Relative Time Feature Engineering\n",
    "    # reltime = np.array(df['Relative Time'])\n",
    "    # round_reltime = np.around(reltime, decimals=0, out=None)\n",
    "    # df_temp.insert(1, \"new Relative Time\", round_reltime, True)\n",
    "    # df_temp['new Relative Time'] = df_temp['new Relative Time'].astype('str')\n",
    "\n",
    "    #calculate the difference between requests from a specific user\n",
    "    df_temp['time_diff'] = df_temp.groupby('Source IP')['Absolute Time'].diff()\n",
    "\n",
    "    #Maybe can remove this (DOUBLE CHECK)\n",
    "    df_temp['time_diff_group'] = df_temp['time_diff'].apply(lambda x: getTimeClass(x.total_seconds()))\n",
    "\n",
    "    #Calculate the Combined Input of URI Hash Status Time\n",
    "    df_temp['Input'] = df_temp['Packet Len'] + '<JOIN>' + df_temp['IP Flags'] + '<JOIN>' + df_temp['TCP Len'] + '<JOIN>' + df_temp['new TCP Ack'] + '<JOIN>' + df_temp['TCP Flags'] + '<JOIN>' + df_temp['TCP Window Size'] + '<JOIN>' + df_temp['Highest Layer(Protocol)']\n",
    "\n",
    "    return df_temp\n",
    "\n",
    "def getSignificantRequest(dataframe, hashThreshold) :\n",
    "    freq = dataframe['Input'].value_counts(normalize=True)\n",
    "\n",
    "    ret = []\n",
    "\n",
    "    index = freq.index\n",
    "    for i in range(len(freq)):\n",
    "        if freq[i] > hashThreshold :\n",
    "            ret.append(index[i])\n",
    "\n",
    "    return ret\n",
    "\n",
    "# def keepOrHash(uri, sig, inputHashRange) :\n",
    "#     if uri in sig :\n",
    "#         return uri\n",
    "#     else :\n",
    "#         return str(int(hashlib.sha1(uri.encode('utf-8')).hexdigest(), 16) % inputHashRange)\n",
    "def keepOrHash(uri, sig, inputHashRange) :\n",
    "    return str(int(hashlib.sha1(uri.encode('utf-8')).hexdigest(), 16) % inputHashRange)\n",
    "\n",
    "def sequentializeDataFrame(df, sig, inputHashRange, seqlen): # add\n",
    "    #create a deepcopy of the original df\n",
    "    df_temp = df.copy()\n",
    "    if type(df_temp['Absolute Time'].iloc[0]) == str:\n",
    "        df_temp['Absolute Time'] = df_temp['Absolute Time'].apply(lambda x: converttodatetime(x, config['SEQUENCELENGTH'])) # add\n",
    "    #converting type of status\n",
    "    df_temp = df_temp.astype({'Source IP' : 'str'})\n",
    "    df_temp = df_temp.astype({'Dest IP' : 'str'})\n",
    "    # df_temp = df_temp.astype({'Relative Time' : 'str'})\n",
    "    df_temp = df_temp.astype({'Packet Len': 'str'})\n",
    "    df_temp = df_temp.astype({'IP Flags' : 'str'})\n",
    "    df_temp = df_temp.astype({'TCP Len' : 'str'})\n",
    "    df_temp = df_temp.astype({'TCP Ack' : 'str'})\n",
    "    df_temp = df_temp.astype({'TCP Flags' : 'str'})\n",
    "    df_temp = df_temp.astype({'TCP Window Size': 'str'})\n",
    "    df_temp = df_temp.astype({'Protocols': 'str'})\n",
    "    df_temp = df_temp.astype({'Highest Layer(Protocol)': 'str'})\n",
    "    df_temp = df_temp.astype({'Info' : 'str'})\n",
    "    df_temp = df_temp.astype({'Input': 'str'})\n",
    "\n",
    "    #Uncomment if you want to hash the Input\n",
    "    df_temp['Input'] = df_temp['Input'].apply(lambda x: keepOrHash(x, sig, inputHashRange))\n",
    "\n",
    "    #create groups based on 1 min interval\n",
    "    df_temp['groups'] = df_temp.groupby('Source IP')['time_diff'].apply(lambda x: x.gt(pd.Timedelta(1, 'm')).cumsum())\n",
    "    df_temp['time_diff'] = df_temp['time_diff'].apply(lambda x: getTimeClass(x.total_seconds()))\n",
    "    #grouping in sequences of 20 length\n",
    "    df_temp['group_len'] = df_temp.groupby(['Source IP', 'Dest IP', 'groups'])['Absolute Time'].rank(method = 'first')\n",
    "    # df_temp['group_len'] = df_temp['group_len'].apply(lambda x: math.ceil(x/20))\n",
    "    df_temp['group_len'] = df_temp['group_len'].apply(lambda x: math.ceil(x/seqlen)) # add\n",
    "\n",
    "    #create groups based on \"remote_addr\" and \"groups\"\n",
    "    df_temp = df_temp.groupby(['Source IP', 'Dest IP', 'groups', 'group_len'])\n",
    "\n",
    "    #aggregation\n",
    "    sr = df_temp['Protocols', 'Info'].agg(lambda x: \"<SEP>\".join(x))\n",
    "    sr['Input'] = df_temp['Input'].agg(lambda x: \"<SEP>\".join(x))\n",
    "    sr.reset_index(inplace=True)\n",
    "    #converting to dataframe\n",
    "    #sr = sr.to_frame()\n",
    "    sr = sr.drop(columns = ['groups', 'group_len'])\n",
    "    return sr\n",
    "\n",
    "def getCountryAgentPair(x, y):\n",
    "    agent = x.split('<SEP>')[0]\n",
    "    country = y.split('<SEP>')[0]\n",
    "\n",
    "    return str(country) + '<JOIN>' + str(agent)\n",
    "\n",
    "def getFirstOnly(y):\n",
    "    country = y.split('<SEP>')[0]\n",
    "\n",
    "    return str(country)\n",
    "\n",
    "\n",
    "#Remove request if Remote Addresses (IP) appear 10 or less times\n",
    "#Because the data is not in chronological form, sort by timestamp to get in chronological form\n",
    "def filterAndSort(df) :\n",
    "    df = df.sort_values(by=['Absolute Time'])\n",
    "    before = len(df)\n",
    "    df = df.groupby('Source IP').filter(lambda x: len(x) > 10)\n",
    "    after = len(df)\n",
    "    df = df.reset_index()\n",
    "\n",
    "    print(\"Before = {}, After = {}\".format(before, after))\n",
    "\n",
    "    return df\n",
    "\n",
    "#Split dataframe into 5s interval\n",
    "def getIntervals(df) :\n",
    "    ret = []\n",
    "    S = pd.to_datetime(df['Absolute Time'])\n",
    "    timebins = (S - S[0]).astype('timedelta64[m]')\n",
    "    timebins = timebins.tolist()\n",
    "    timebins = [math.floor(time/1) for time in timebins]\n",
    "    timebins = [pd.Series(timebins)]\n",
    "\n",
    "    for i, g in df.groupby(timebins):\n",
    "        ret.append(g.reset_index(drop=True))\n",
    "\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2eb8032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wesleyjtann/miniconda3/envs/ddos/lib/python3.7/site-packages/ipykernel_launcher.py:3: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before = 20533086, After = 20531528\n",
      "Before = 593871, After = 593462\n"
     ]
    }
   ],
   "source": [
    "# config = loadConfig()\n",
    "with open('light_config.yaml', \"r\") as ymlfile:\n",
    "    config = yaml.load(ymlfile)\n",
    "\n",
    "dfA = pd.read_csv(config['datapath']['a'], parse_dates=['Absolute Time'])\n",
    "dfN1 = pd.read_csv(config['datapath']['n1'], parse_dates=['Absolute Time'])\n",
    "\n",
    "# #load N2\n",
    "# dfN2 = pd.read_csv(config['datapath']['n2'], parse_dates=['Absolute Time'])\n",
    "\n",
    "#Remove request if Remote Addresses (IP) appear 10 or less times\n",
    "#Because the data is not in chronological form, sort by timestamp to get in chronological form\n",
    "dfA = filterAndSort(dfA)\n",
    "dfN1 = filterAndSort(dfN1)\n",
    "# dfN2 = filterAndSort(dfN2)\n",
    "\n",
    "#Prepares A1 and N1 for sequentializing\n",
    "df_normal = prepDataFrame(dfN1, config['variablesHash']['agentHashRange'], config['variablesHash']['queryHashRange'])\n",
    "# df_normal2 = prepDataFrame(dfN2, config['variablesHash']['agentHashRange'], config['variablesHash']['queryHashRange'])\n",
    "significantNormal = getSignificantRequest(df_normal, config['variablesHash']['inputHashThreshold'])\n",
    "\n",
    "#Sequentializes A1 and N1\n",
    "df_normal = sequentializeDataFrame(df_normal, significantNormal, config['variablesHash']['inputHashRange'], config['SEQUENCELENGTH']) # add\n",
    "# df_normal2 = sequentializeDataFrame(df_normal2, significantNormal, config['variablesHash']['inputHashRange'], config['SEQUENCELENGTH']) # add\n",
    "\n",
    "#Prepares the Histogram for Agent and Country\n",
    "df_normal['Histo'] = df_normal.apply(lambda row: getCountryAgentPair(row['Protocols'], row['Info']), axis=1)\n",
    "# df_normal2['Histo'] = df_normal2.apply(lambda row: getCountryAgentPair(row['Protocols'], row['Info']), axis=1)\n",
    "\n",
    "#Get Agent\n",
    "df_normal['Protocols'] = df_normal.apply(lambda row: getFirstOnly(row['Protocols']), axis=1)\n",
    "# df_normal2['Protocols'] = df_normal2.apply(lambda row: getFirstOnly(row['Protocols']), axis=1)\n",
    "\n",
    "#Get Country\n",
    "df_normal['Info'] = df_normal.apply(lambda row: getFirstOnly(row['Info']), axis=1)\n",
    "# df_normal2['Info'] = df_normal2.apply(lambda row: getFirstOnly(row['Info']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1edc4997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e650e1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source IP</th>\n",
       "      <th>Dest IP</th>\n",
       "      <th>Protocols</th>\n",
       "      <th>Info</th>\n",
       "      <th>Input</th>\n",
       "      <th>Histo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126.120.0.39</td>\n",
       "      <td>71.126.222.64</td>\n",
       "      <td>raw:ip:tcp</td>\n",
       "      <td>80 → 46689 [SYN, ACK] Seq=0 Ack=1 Win=65535 Le...</td>\n",
       "      <td>117&lt;SEP&gt;45&lt;SEP&gt;117&lt;SEP&gt;49&lt;SEP&gt;117&lt;SEP&gt;101&lt;SEP&gt;...</td>\n",
       "      <td>80 → 46689 [SYN, ACK] Seq=0 Ack=1 Win=65535 Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>126.120.0.39</td>\n",
       "      <td>71.126.222.64</td>\n",
       "      <td>raw:ip:tcp</td>\n",
       "      <td>80 → 46689 [PSH, ACK] Seq=13049 Ack=123 Win=65...</td>\n",
       "      <td>168&lt;SEP&gt;25&lt;SEP&gt;168&lt;SEP&gt;25&lt;SEP&gt;168&lt;SEP&gt;25&lt;SEP&gt;1...</td>\n",
       "      <td>80 → 46689 [PSH, ACK] Seq=13049 Ack=123 Win=65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126.120.0.39</td>\n",
       "      <td>71.126.222.64</td>\n",
       "      <td>raw:ip:tcp</td>\n",
       "      <td>80 → 46689 [PSH, ACK] Seq=27385 Ack=123 Win=65...</td>\n",
       "      <td>124&lt;SEP&gt;124&lt;SEP&gt;168&lt;SEP&gt;25&lt;SEP&gt;168&lt;SEP&gt;25&lt;SEP&gt;...</td>\n",
       "      <td>80 → 46689 [PSH, ACK] Seq=27385 Ack=123 Win=65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126.120.0.39</td>\n",
       "      <td>71.126.222.64</td>\n",
       "      <td>raw:ip:tcp</td>\n",
       "      <td>80 → 46689 [PSH, ACK] Seq=40097 Ack=123 Win=65...</td>\n",
       "      <td>25&lt;SEP&gt;124&lt;SEP&gt;168&lt;SEP&gt;25&lt;SEP&gt;114&lt;SEP&gt;114&lt;SEP&gt;...</td>\n",
       "      <td>80 → 46689 [PSH, ACK] Seq=40097 Ack=123 Win=65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>126.120.0.39</td>\n",
       "      <td>71.126.222.64</td>\n",
       "      <td>raw:ip:tcp</td>\n",
       "      <td>80 → 46690 [PSH, ACK] Seq=18593 Ack=122 Win=65...</td>\n",
       "      <td>118&lt;SEP&gt;45&lt;SEP&gt;224&lt;SEP&gt;224&lt;SEP&gt;224&lt;SEP&gt;224&lt;SEP...</td>\n",
       "      <td>80 → 46690 [PSH, ACK] Seq=18593 Ack=122 Win=65...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Source IP        Dest IP   Protocols  \\\n",
       "0  126.120.0.39  71.126.222.64  raw:ip:tcp   \n",
       "1  126.120.0.39  71.126.222.64  raw:ip:tcp   \n",
       "2  126.120.0.39  71.126.222.64  raw:ip:tcp   \n",
       "3  126.120.0.39  71.126.222.64  raw:ip:tcp   \n",
       "4  126.120.0.39  71.126.222.64  raw:ip:tcp   \n",
       "\n",
       "                                                Info  \\\n",
       "0  80 → 46689 [SYN, ACK] Seq=0 Ack=1 Win=65535 Le...   \n",
       "1  80 → 46689 [PSH, ACK] Seq=13049 Ack=123 Win=65...   \n",
       "2  80 → 46689 [PSH, ACK] Seq=27385 Ack=123 Win=65...   \n",
       "3  80 → 46689 [PSH, ACK] Seq=40097 Ack=123 Win=65...   \n",
       "4  80 → 46690 [PSH, ACK] Seq=18593 Ack=122 Win=65...   \n",
       "\n",
       "                                               Input  \\\n",
       "0  117<SEP>45<SEP>117<SEP>49<SEP>117<SEP>101<SEP>...   \n",
       "1  168<SEP>25<SEP>168<SEP>25<SEP>168<SEP>25<SEP>1...   \n",
       "2  124<SEP>124<SEP>168<SEP>25<SEP>168<SEP>25<SEP>...   \n",
       "3  25<SEP>124<SEP>168<SEP>25<SEP>114<SEP>114<SEP>...   \n",
       "4  118<SEP>45<SEP>224<SEP>224<SEP>224<SEP>224<SEP...   \n",
       "\n",
       "                                               Histo  \n",
       "0  80 → 46689 [SYN, ACK] Seq=0 Ack=1 Win=65535 Le...  \n",
       "1  80 → 46689 [PSH, ACK] Seq=13049 Ack=123 Win=65...  \n",
       "2  80 → 46689 [PSH, ACK] Seq=27385 Ack=123 Win=65...  \n",
       "3  80 → 46689 [PSH, ACK] Seq=40097 Ack=123 Win=65...  \n",
       "4  80 → 46690 [PSH, ACK] Seq=18593 Ack=122 Win=65...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_normal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd3954ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min hash:  2\n",
      "max hash:  249\n",
      "number of hashes:  174\n"
     ]
    }
   ],
   "source": [
    "# dfnorm_tmp['Input'][0].split('<SEP>')\n",
    "df_normal['Split_Input'] = df_normal['Input'].apply(lambda x: x.split('<SEP>'))\n",
    "\n",
    "# dfnorm_tmp['Split_Input'].value_counts()\n",
    "df_normal['max_tmp'] = df_normal.Split_Input.apply(max)\n",
    "print(\"min hash: \", min(df_normal['max_tmp'].astype(int).unique()))\n",
    "print(\"max hash: \", max(df_normal['max_tmp'].astype(int).unique()))\n",
    "print(\"number of hashes: \", df_normal['max_tmp'].sort_values().nunique()) #value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de48f2d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting number of hashes \n",
    "\n",
    "# dfnorm_tmp['Input'][0].split('<SEP>')\n",
    "df_normal['Split_Input'] = df_normal['Input'].apply(lambda x: x.split('<SEP>'))\n",
    "df_normal.head()\n",
    "\n",
    "\n",
    "# dfnorm_tmp['Split_Input'].value_counts()\n",
    "max_tmp = df_normal.Split_Input.apply(max)\n",
    "\n",
    "max_list = [int(i) for i in max_tmp.tolist()]\n",
    "max(max_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28bc2173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(max_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3179e8e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e17d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    #Save the dataframe as artefacts.\n",
    "    df_normal.to_csv(r'' + config['metadata']['uniqueID'] + '/' + config['metadata']['artefact'] + '/' + 'N1.csv', index = None, header=True)\n",
    "\n",
    "    df_attack_intervals = getIntervals(dfA)\n",
    "\n",
    "    # if config['ONLINETRAINING'] :\n",
    "    count = 0\n",
    "    for df_int in df_attack_intervals[:-config['metadata']['attackintervals']] :\n",
    "        df_attack = prepDataFrame(df_int, config['variablesHash']['agentHashRange'], config['variablesHash']['queryHashRange'])\n",
    "        df_attack = sequentializeDataFrame(df_attack, significantNormal, config['variablesHash']['inputHashRange'], config['SEQUENCELENGTH']) # add\n",
    "        df_attack['Histo'] = df_attack.apply(lambda row: getCountryAgentPair(row['Protocols'], row['Info']), axis=1)\n",
    "        df_attack['Protocols'] = df_attack.apply(lambda row: getFirstOnly(row['Protocols']), axis=1)\n",
    "        df_attack['Info'] = df_attack.apply(lambda row: getFirstOnly(row['Info']), axis=1)\n",
    "        df_attack.to_csv(r'' + config['metadata']['uniqueID'] + '/' + config['metadata']['artefact'] + '/' + 'A1_' + str(count) + '.csv', index = None, header=True)\n",
    "        count = count + 1\n",
    "    # else :\n",
    "    df_attack_batch = []\n",
    "    # count = 0\n",
    "    for df_int in df_attack_intervals[:-config['metadata']['attackintervals']] :\n",
    "        df_attack = prepDataFrame(df_int, config['variablesHash']['agentHashRange'], config['variablesHash']['queryHashRange'])\n",
    "        df_attack = sequentializeDataFrame(df_attack, significantNormal, config['variablesHash']['inputHashRange'], config['SEQUENCELENGTH']) # add\n",
    "        df_attack['Histo'] = df_attack.apply(lambda row: getCountryAgentPair(row['Protocols'], row['Info']), axis=1)\n",
    "        df_attack['Protocols'] = df_attack.apply(lambda row: getFirstOnly(row['Protocols']), axis=1)\n",
    "        df_attack['Info'] = df_attack.apply(lambda row: getFirstOnly(row['Info']), axis=1)\n",
    "        df_attack_batch.append(df_attack)\n",
    "        # count = count + 1\n",
    "\n",
    "    df_attack = pd.concat(df_attack_batch)\n",
    "    df_attack.to_csv(r'' + config['metadata']['uniqueID'] + '/' + config['metadata']['artefact'] + '/' + 'A1_full.csv', index = None, header=True)\n",
    "\n",
    "\n",
    "    # df_normal2.to_csv(r'' + config['metadata']['uniqueID'] + '/' + config['metadata']['artefact'] + '/' + 'N2.csv', index = None, header=True) # add\n",
    "    df_test = [] \n",
    "    # #N2 test set\n",
    "    # df_test.append(df_normal2) # remove?\n",
    "\n",
    "    # A2 test set\n",
    "    for df_int in df_attack_intervals[-config['metadata']['attackintervals']:] :\n",
    "        df_attack = prepDataFrame(df_int, config['variablesHash']['agentHashRange'], config['variablesHash']['queryHashRange'])\n",
    "        # df_attack.to_csv(r'' + config['metadata']['uniqueID'] + '/' + config['metadata']['artefact'] + '/' + 'A2_' + str(count) + '(PreSequentialize).csv', index = None, header=True)\n",
    "        df_attack = sequentializeDataFrame(df_attack, significantNormal, config['variablesHash']['inputHashRange'], config['SEQUENCELENGTH']) # add\n",
    "        df_attack['Histo'] = df_attack.apply(lambda row: getCountryAgentPair(row['Protocols'], row['Info']), axis=1)\n",
    "        df_attack['Protocols'] = df_attack.apply(lambda row: getFirstOnly(row['Protocols']), axis=1)\n",
    "        df_attack['Info'] = df_attack.apply(lambda row: getFirstOnly(row['Info']), axis=1)\n",
    "        df_test.append(df_attack)\n",
    "\n",
    "    df_test = pd.concat(df_test) \n",
    "    df_test.to_csv(r'' + config['metadata']['uniqueID'] + '/' + config['metadata']['artefact'] + '/' + 'TEST.csv', index = None, header=True)\n",
    "    \n",
    "    \n",
    "    print(\"*****     Ending Preprocessing     ******\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ddos",
   "language": "python",
   "name": "ddos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
